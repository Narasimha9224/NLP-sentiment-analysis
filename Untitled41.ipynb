import nltk
nltk.download('stopwords')
nltk.download('wordnet')
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
import re
try:
    df = pd.read_csv('customer_reviews.csv')
    print("Dataset loaded successfully.")
    print(df.head())
    print(f"Dataset shape: {df.shape}")
except FileNotFoundError:
    print("Error: 'customer_reviews.csv' not found. Creating a dummy dataset.")
    data = {'review_text': [
        "This product is amazing! I love it.",
        "Terrible experience, very disappointed.",
        "It's okay, nothing special.",
        "Highly recommend, worth every penny.",
        "Worst purchase ever, completely dissatisfied.",
        "Good quality for the price.",
        "Not bad, but could be better.",
        "Fantastic service and fast delivery.",
        "I'm so angry with this product, a total waste of money.",
        "Very happy with my purchase."
    ],
            'sentiment': [
                'positive', 'negative', 'neutral', 'positive', 'negative',
                'positive', 'neutral', 'positive', 'negative', 'positive'
            ]}
    df = pd.DataFrame(data)
    df.to_csv('customer_reviews.csv', index=False)
    print("Dummy dataset created and saved as 'customer_reviews.csv'.")
    print(df.head())
stop_words = set(stopwords.words('english'))
stemmer = PorterStemmer()

def preprocess_text(text):
    text = text.lower()  
    text = re.sub(r'[^a-z\s]', '', text)  
    words = text.split()
    words = [word for word in words if word not in stop_words]  
    words = [stemmer.stem(word) for word in words]  
    return ' '.join(words)

df['processed_review'] = df['review_text'].apply(preprocess_text)
print("\nProcessed reviews:")
print(df[['review_text', 'processed_review']].head())
X = df['processed_review']
y = df['sentiment']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42, stratify=y) 

tfidf_vectorizer = TfidfVectorizer(max_features=5000) 
X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
X_test_tfidf = tfidf_vectorizer.transform(X_test)

print(f"\nTF-IDF vectorizer fitted. Vocabulary size: {len(tfidf_vectorizer.vocabulary_)}")
print(f"Shape of X_train_tfidf: {X_train_tfidf.shape}")
print(f"Shape of X_test_tfidf: {X_test_tfidf.shape}")
logistic_model = LogisticRegression(max_iter=1000, solver='liblinear') 
logistic_model.fit(X_train_tfidf, y_train)

print("\nLogistic Regression model trained.")


y_pred = logistic_model.predict(X_test_tfidf)

print("\n--- Model Evaluation ---")
print(f"Accuracy: {accuracy_score(y_test, y_pred):.4f}")
print("\nClassification Report:")
print(classification_report(y_test, y_pred))
def predict_sentiment(review_text):
    processed_new_review = preprocess_text(review_text)
    new_review_tfidf = tfidf_vectorizer.transform([processed_new_review])
    prediction = logistic_model.predict(new_review_tfidf)
    probability = logistic_model.predict_proba(new_review_tfidf)
    sentiment_labels = logistic_model.classes_
    prob_dict = dict(zip(sentiment_labels, probability[0]))
    return prediction[0], prob_dict

print("\n--- Prediction on New Review ---")
new_review1 = "This movie was absolutely fantastic, truly a masterpiece!"
sentiment1, prob1 = predict_sentiment(new_review1)
print(f"Review: '{new_review1}' -> Predicted Sentiment: {sentiment1}, Probabilities: {prob1}")

new_review2 = "I'm really disappointed with the product quality. It broke on the first day."
sentiment2, prob2 = predict_sentiment(new_review2)
print(f"Review: '{new_review2}' -> Predicted Sentiment: {sentiment2}, Probabilities: {prob2}")

new_review3 = "The service was average, nothing special but not bad either."
sentiment3, prob3 = predict_sentiment(new_review3)
print(f"Review: '{new_review3}' -> Predicted Sentiment: {sentiment3}, Probabilities: {prob3}")
